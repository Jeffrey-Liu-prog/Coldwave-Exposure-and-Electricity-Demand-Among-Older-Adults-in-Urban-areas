{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f623af8-af2d-48b9-a566-f4216733ac9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5d9a56-0f5c-463d-ba1d-5697f494c9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the rolling percentiles for each coordinate\n",
    "def calculate_rolling_percentiles(file_path, output_file=None):\n",
    "    # Load the data\n",
    "    data = pd.read_csv(file_path)\n",
    "\n",
    "    # Filter out temperature larger than 15â„ƒ\n",
    "    data = data[data['tas'] < 288.15]\n",
    "\n",
    "    # Create a datetime column from year, month, and day\n",
    "    data['time'] = pd.to_datetime(data[['year', 'month', 'day']])\n",
    "\n",
    "    # Sort by latitude, longitude, and time for consistency\n",
    "    data.sort_values(by=['latitude', 'longitude', 'time'], inplace=True)\n",
    "\n",
    "    # Extract day of the year for grouping\n",
    "    data['DayOfYear'] = data['time'].dt.day_of_year\n",
    "    \n",
    "    # Perform a grouped rolling calculation\n",
    "    # Group by latitude, longitude, and day of the year\n",
    "    grouped = data.groupby(['latitude', 'longitude', 'DayOfYear'])\n",
    "    \n",
    "    # Calculate the 10th percentile within the rolling window centered\n",
    "    data['PercentileQ10'] = grouped['tas'].transform(lambda x: x.rolling(window=7, center=True, min_periods=1).quantile(0.1))\n",
    "      \n",
    "    # Save or return the results\n",
    "    if output_file:\n",
    "        data.to_csv(output_file, index=False)\n",
    "    else:\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a3fc57-206c-4f22-b2be-35e2f3d92b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify cold wave by if the cold days are consecutive\n",
    "def identify_cold_wave_events(file_path):\n",
    "    # Load the data\n",
    "    data = pd.read_csv(file_path, parse_dates=['time'])\n",
    "\n",
    "    # Sort data by latitude, longitude, and time to ensure chronological order\n",
    "    data.sort_values(by=['latitude', 'longitude', 'time'], inplace=True)\n",
    "\n",
    "    # Group by latitude and longitude\n",
    "    def check_continuous_cold_wave(group):\n",
    "        # Calculate the difference between consecutive days\n",
    "        group['date_diff'] = group['time'].diff().dt.days\n",
    "\n",
    "        # Identify the start of new cold wave sequences\n",
    "        group['new_cw_sequence'] = (group['date_diff'] > 1) | (group['date_diff'].isna())\n",
    "        \n",
    "        # Mark sequences of cold wave days\n",
    "        group['cw_sequence'] = group['new_cw_sequence'].cumsum()\n",
    "\n",
    "        # Count the number of days in each cold wave sequence\n",
    "        cw_counts = group.groupby('cw_sequence')['IsColdWave'].transform('sum')\n",
    "\n",
    "        # Determine valid cold wave events (sequences of at least two days)\n",
    "        group['IsColdWaveEvent'] = (group['IsColdWave'] & (cw_counts >= 2))\n",
    "\n",
    "        # Clean up temporary columns\n",
    "        group.drop(['date_diff', 'new_cw_sequence', 'cw_sequence'], axis=1, inplace=True)\n",
    "        return group\n",
    "\n",
    "    # Apply the function to each group defined by unique lat and lon\n",
    "    data = data.groupby(['latitude', 'longitude'],group_keys=True).apply(check_continuous_cold_wave)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e737d1-4a03-45e8-9fa2-8b847479c65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify future cold wave\n",
    "\n",
    "def mark_and_check_cold_wave_days(group):\n",
    "    # Ensure 'time' is in datetime format and sort the group by 'time'\n",
    "    group['time'] = pd.to_datetime(group['time'])\n",
    "    group = group.sort_values('time').reset_index(drop=True)\n",
    "    \n",
    "    # Initialize 'cold_wave_valid' to False for all entries in the group\n",
    "    group['cold_wave_valid'] = False\n",
    "    \n",
    "    # Determine potential cold wave days\n",
    "    group['IsColdWave'] = (group['tas'] <= group['Threshold']).astype(int)\n",
    "    \n",
    "    # Identify changes in 'IsColdWave' to mark sequences\n",
    "    group['IsColdWaveChange'] = group['IsColdWave'].ne(group['IsColdWave'].shift()).cumsum()\n",
    "    \n",
    "    # Group by 'IsColdWaveChange' to identify sequences\n",
    "    for seq_id, seq_group in group.groupby('IsColdWaveChange'):\n",
    "        is_cold_wave = seq_group['IsColdWave'].iloc[0]\n",
    "        sequence_length = len(seq_group)\n",
    "        \n",
    "        if is_cold_wave == 1 and sequence_length >= 2:\n",
    "            # Check if dates are consecutive\n",
    "            date_diffs = seq_group['time'].diff().dt.days.fillna(1)\n",
    "            if date_diffs.eq(1).all():\n",
    "                group.loc[seq_group.index, 'cold_wave_valid'] = True\n",
    "                \n",
    "    # Clean up temporary columns\n",
    "    group.drop(['IsColdWaveChange'], axis=1, inplace=True)\n",
    "    \n",
    "    return group"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
